{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y21Qi3oF8qnI"
   },
   "source": [
    "# 1 -Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ULQisql8iGE",
    "outputId": "03da091d-e09c-481a-dd40-30c6b07376e4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-_yLhwN8xgf"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiMSbC139GRb",
    "outputId": "28204cf3-a9a6-4c23-a4a8-4c51fec1ebcc"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download -d wanderdust/skin-lesion-analysis-toward-melanoma-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I9DCzWl9U-Y",
    "outputId": "e0dc9663-a7c0-4fba-d85d-1d02ab4d2e4b"
   },
   "outputs": [],
   "source": [
    "! unzip /content/skin-lesion-analysis-toward-melanoma-detection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWTtfKp-_GIe"
   },
   "source": [
    "# 2 - Explore the data and prepare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXEuc8SEyei8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "bBSjQ_dNbtbP",
    "outputId": "9c8c7c66-09d3-4ddd-9d31-482b92e19f85"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKasGSlObxkT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_IH0YSA_EVS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os \n",
    "import cv2\n",
    "import PIL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJgyEfwUAthg"
   },
   "outputs": [],
   "source": [
    "Lables = [ 'nevus', 'seborrheic_keratosis' ,'melanoma' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qljYcJyIWFFg"
   },
   "outputs": [],
   "source": [
    "train_dir = '/content/skin-lesions/train'\n",
    "test_dir = '/content/skin-lesions/test'\n",
    "val_dir = '/content/skin-lesions/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBgP_BERWGPs",
    "outputId": "79f1030e-c08a-47d9-c627-b959eec61dbe"
   },
   "outputs": [],
   "source": [
    "def GetDatasetSize(path):\n",
    "    num_of_image = {}\n",
    "    for folder in os.listdir(path):\n",
    "        # Counting the Number of Files in the Folder\n",
    "        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n",
    "    return num_of_image;\n",
    "    \n",
    "train_set = GetDatasetSize(train_dir)\n",
    "val_set = GetDatasetSize(val_dir)\n",
    "test_set = GetDatasetSize(test_dir)\n",
    "print(train_set,\"\\n\\n\",val_set,\"\\n\\n\",test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "fc5xcVt-WdFz",
    "outputId": "223e97a4-6694-4e8c-a8bf-88de994abeda"
   },
   "outputs": [],
   "source": [
    "labels = list(train_set.keys())\n",
    "train_list = list(train_set.values())\n",
    "val_list = list(val_set.values())\n",
    "test_list = list(test_set.values())\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, train_list, width, label='Train')\n",
    "rects2 = ax.bar(x, val_list, width, label='Val')\n",
    "rects3 = ax.bar(x + width, test_list, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Images Count')\n",
    "ax.set_title('Dataset')\n",
    "ax.set_xticks(x, labels)\n",
    "plt.xticks(rotation=15)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04UEq0M0_Nug"
   },
   "outputs": [],
   "source": [
    "def Get_data(train_dir , test_dir , val_dir ):\n",
    "  x_train =[]\n",
    "  y_train =[]\n",
    "  x_test = []\n",
    "  y_test = []\n",
    "  x_val =  []\n",
    "  y_val =  []\n",
    "  train_dir_list = os.listdir(train_dir)\n",
    "  for i in range(len(train_dir_list)):\n",
    "    sub_dir = os.path.join(train_dir , Lables[i])\n",
    "    sub_dir_list = os.listdir(sub_dir)\n",
    "    for j in range(len(sub_dir_list)):\n",
    "       if str(sub_dir_list[j]).split('.')[1] =='jpg' :\n",
    "         x_train.append(os.path.join(sub_dir , sub_dir_list[j]))\n",
    "         y_train.append(i)\n",
    "  test_dir_list = os.listdir(test_dir)    \n",
    "  for i in range(len(test_dir_list)):\n",
    "    sub_dir = os.path.join(test_dir , Lables[i])\n",
    "    sub_dir_list = os.listdir(sub_dir)\n",
    "    for j in range(len(sub_dir_list)):\n",
    "      if str(sub_dir_list[j]).split('.')[1] =='jpg' :\n",
    "         x_test.append(os.path.join(sub_dir , sub_dir_list[j]))\n",
    "         y_test.append(i) \n",
    "  val_dir_list = os.listdir(val_dir)    \n",
    "  for i in range(len(val_dir_list)):\n",
    "    sub_dir = os.path.join(val_dir , Lables[i])\n",
    "    sub_dir_list = os.listdir(sub_dir)\n",
    "    for j in range(len(sub_dir_list)):\n",
    "       if str(sub_dir_list[j]).split('.')[1] =='jpg' :\n",
    "         x_val.append(os.path.join(sub_dir , sub_dir_list[j]))\n",
    "         y_val.append(i) \n",
    "  return np.array(x_train) ,np.array(x_test) , np.array(x_val) , np.array(y_train) , np.array(y_test) , np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RYAFIQPLzAw"
   },
   "outputs": [],
   "source": [
    "x_train ,x_test , x_val , y_train , y_test , y_val = Get_data(train_dir,test_dir,val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWtWyUIZMV_p",
    "outputId": "52414a63-0719-4aef-f530-62fcd3234d79"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape==x_train.shape)\n",
    "print(y_test.shape==x_test.shape)\n",
    "print(y_val.shape==x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fvy501RUM6v0",
    "outputId": "07288105-2443-4d9f-ded9-71aa65367efd"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "LYmnlsnDNdxf",
    "outputId": "3bb47db0-6bec-4ab8-fab9-a92faacdc751"
   },
   "outputs": [],
   "source": [
    "# we will see data split counts\n",
    "plt.bar(['train' , 'test' ,'val'] , height =[len(x_train) , len(x_test) ,len(x_val)]\n",
    "         )\n",
    "plt.xlabel('data_')\n",
    "plt.ylabel('Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gxy43QcM_3zR"
   },
   "outputs": [],
   "source": [
    "def image_show(index):\n",
    "  image = np.array(cv2.imread(x_train[index]))\n",
    "  print(image.shape)\n",
    "  plt.imshow(image)\n",
    "  plt.title(Lables[y_train[index]])\n",
    "  plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "5kMMG7deAXyj",
    "outputId": "c9cdfa4a-5c07-4c5a-e694-81e83259a467"
   },
   "outputs": [],
   "source": [
    "image_show(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5ek6ey60gNn"
   },
   "outputs": [],
   "source": [
    "def image_show_resized(index , gray):\n",
    "  if gray :\n",
    "    image = image = cv2.imread(x_train[index] , cv2.IMREAD_GRAYSCALE)\n",
    "  else :\n",
    "    image = cv2.imread(x_train[index] )\n",
    "  image = cv2.resize(image , (150,150))\n",
    "  image = np.array(image)\n",
    "  print(image.shape)\n",
    "  plt.imshow(image)\n",
    "  plt.title(Lables[y_train[index]])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "I0bMlOGo3-2g",
    "outputId": "3021ed15-6b75-415a-8173-961166b433b4"
   },
   "outputs": [],
   "source": [
    "image_show_resized(1700 , gray = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxfj8jfe4dVM"
   },
   "outputs": [],
   "source": [
    "# we will see data distribution\n",
    "def plot_data_distribution(y_train):\n",
    "  unique, counts = np.unique(y_train, return_counts=True)\n",
    "  plt.bar([Lables[i] for i in unique] , height = counts , color ='green')\n",
    "  plt.xlabel('data_unique')\n",
    "  plt.xlabel('data_frequency')\n",
    "  plt.show()\n",
    "  for i in range(len(unique)):\n",
    "    print(Lables[i] ,':' , counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "-qjFzdO_6PoM",
    "outputId": "450861cc-3686-4bac-9abb-b50dbd10aeaa"
   },
   "outputs": [],
   "source": [
    "plot_data_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqLsXxOp65mo"
   },
   "source": [
    "# 3 - prepare the data for training and build data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OIyXtO6dpw6V",
    "outputId": "0e947f63-19a6-4a98-cd3a-9b4dc670f7fa"
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeaOGvEJTLbk"
   },
   "outputs": [],
   "source": [
    "def image_loaders(image_paths):\n",
    "  images =[]\n",
    "  for i in range(len(image_paths)):\n",
    "    image = cv2.imread(image_paths[i] )\n",
    "    image = cv2.resize(image , (150,150))\n",
    "    image = np.array(image)\n",
    "    images.append(image)\n",
    "  images = np.array(images)\n",
    "  images = images/255\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n67TQXGVW_rU"
   },
   "outputs": [],
   "source": [
    "x_train = image_loaders(x_train)\n",
    "x_val = image_loaders(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcEafZ9_U0eb"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADJe6XvcSvDF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "train_datagen = image.ImageDataGenerator(zoom_range = 0.2, shear_range = 0.2 , rescale = 1./255 , horizontal_flip = True, vertical_flip = True)\n",
    "val_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = image.ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pztmVBboIHL2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IqyShmp_gqP"
   },
   "outputs": [],
   "source": [
    "# we need to shuffle the data\n",
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, to_categorical(y_train), random_state=20)\n",
    "x_test, y_test = shuffle(x_test, to_categorical(y_test), random_state=20)\n",
    "x_val, y_val = shuffle(x_val,to_categorical(y_val), random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaDZzjGKBWoK"
   },
   "source": [
    "# 4 - build the model and compute loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIgQUPtzBU7X"
   },
   "outputs": [],
   "source": [
    "# build_model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 3 , activation = 'softmax'))\n",
    "model.compile(optimizer = \"adam\" , loss = keras.losses.CategoricalCrossentropy() , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSDdZ33_ZWwG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model\n",
    "# Adding Model check point Callback\n",
    "mc = ModelCheckpoint(filepath=\"oc_cnn_best_model.hdf5\",\n",
    "                     verbose= 0,\n",
    "                     save_best_only= True\n",
    "                     );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RP8cxBEVBt4w",
    "outputId": "989a1cba-3e42-4988-825a-81f1f051f8c1"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jF9kX_gsTbAa",
    "outputId": "8430092c-ff50-4d89-fbdf-6ab74aff098d"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
    "history1 = model.fit(train_datagen.flow(x_train , y_train) \n",
    "          ,epochs=5\n",
    "          ,verbose=1,\n",
    "          validation_data=val_datagen.flow(x_val , y_val),\n",
    "          callbacks=[learning_rate_reduction ,mc]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmVyOlphZ567"
   },
   "outputs": [],
   "source": [
    "x_test = image_loaders(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dr9n3saOZqo6",
    "outputId": "6af99269-d61d-4bf9-bdbd-b9261a9eb211"
   },
   "outputs": [],
   "source": [
    "# Checking the Accuracy of the Model \n",
    "accuracy_cnn = model.evaluate(x_test , y_test)[1] \n",
    "print(f\"The accuracy of the model is = {accuracy_cnn*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "Uc48Ho-EZwN9",
    "outputId": "17275661-9f67-4833-b08b-585476551904"
   },
   "outputs": [],
   "source": [
    "# Plot model performance\n",
    "acc = history1.history['accuracy']\n",
    "val_acc = history1.history['val_accuracy']\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "epochs_range = range(1, len(history1.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-o3xFi8ecOXV"
   },
   "source": [
    "vgg-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqgLVYkAcN0S",
    "outputId": "882caa56-e1d5-4d21-ff7c-ff80a775872b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    input_shape=(150,150,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWbeJj835mo8"
   },
   "outputs": [],
   "source": [
    "layers =  base_model.get_layer('vgg16').layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYivsgggcTjh"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "\n",
    "vgg_model = Sequential()\n",
    "vgg_model.add(base_model)\n",
    "vgg_model.add(layers.Flatten())\n",
    "vgg_model.add(layers.Dropout(0.25))\n",
    "vgg_model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "vgg_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YIqlhlNmGSq",
    "outputId": "545c0320-4236-4459-c340-a95e3013ac5a"
   },
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7GQpHg3cWDy",
    "outputId": "b7aea3bc-10c5-48ba-c0c9-cbc78c4d1213"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
    "history2 = vgg_model.fit(train_datagen.flow(x_train , y_train) \n",
    "          ,epochs=1\n",
    "          ,verbose=1,\n",
    "          validation_data=val_datagen.flow(x_val , y_val),\n",
    "          callbacks=[learning_rate_reduction ,mc]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8ZXurYKcdGU",
    "outputId": "2240b856-8536-4876-9b27-2899e0c1cbcf"
   },
   "outputs": [],
   "source": [
    "# Checking the Accuracy of the Model \n",
    "accuracy_vgg = vgg_model.evaluate(x_test , y_test)[1] \n",
    "print(f\"The accuracy of the model is = {accuracy_vgg*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "KSmsCg3_crRX",
    "outputId": "d522a4d1-3802-40f9-e156-8a2933d0d0a5"
   },
   "outputs": [],
   "source": [
    "# Plot model performance\n",
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "epochs_range = range(1, len(history2.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "5MI8MsfBdR1P",
    "outputId": "b2a8c69d-253c-4eb9-d8d0-db3e4e3396c4"
   },
   "outputs": [],
   "source": [
    "algos = ['CNN', 'VGG16']\n",
    "accuracy = [accuracy_cnn, accuracy_vgg]\n",
    "accuracy = np.floor([i * 100 for i in accuracy])\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(algos, accuracy, color ='red', width = 0.3)\n",
    " \n",
    "plt.xlabel(\"Algorithms Applied\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex6SVtEJdaHM"
   },
   "source": [
    "gradient-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VSGg0QSd4Pc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAd5XSvedo88"
   },
   "outputs": [],
   "source": [
    "orig = cv2.imread('//content/skin-lesions/test/nevus/ISIC_0012149.jpg')\n",
    "resized = cv2.resize(orig, (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-LLgVtRgNjY",
    "outputId": "3ac6ed79-96b5-41dc-a81e-50c86e7fde54"
   },
   "outputs": [],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "eBP74PSsgF_r",
    "outputId": "e207750e-732e-4b78-f46d-6ad8df6da8a1"
   },
   "outputs": [],
   "source": [
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPvPQAyNdvSW",
    "outputId": "61bb4fb2-be9b-4f21-c4bf-07038f21441e"
   },
   "outputs": [],
   "source": [
    "image = np.expand_dims(np.array(resized)/255,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSHZpat8gbBM"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(image)\n",
    "i = np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IylEMuQigp66"
   },
   "outputs": [],
   "source": [
    "def compute_cam(model , layername , orig ):\n",
    "  gradModel = Model(inputs=[model.inputs], outputs= [model.get_layer(layername).output, model.output])\n",
    "  with tf.GradientTape() as tape:\n",
    "     inputs = tf.cast(image, tf.float32)\n",
    "     (convOutputs, predictions) = gradModel(inputs)\n",
    "     loss = predictions[:, i]\n",
    "  grads = tape.gradient(loss, convOutputs)\n",
    "  castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "  castGrads = tf.cast(grads > 0, \"float32\")\n",
    "  guidedGrads = castConvOutputs * castGrads * grads\n",
    "  convOutputs = convOutputs[0]\n",
    "  guidedGrads = guidedGrads[0]\n",
    "  weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "  cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "  (w, h) = (image.shape[2], image.shape[1])\n",
    "  heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "  numer = heatmap - np.min(heatmap)\n",
    "  denom = (heatmap.max() - heatmap.min()) + 1e-8\n",
    "  heatmap = numer / denom\n",
    "  heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "  # then we will overlay the image with heatmap\n",
    "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "  output = cv2.addWeighted(orig, 0.5, heatmap, 0.5, 0)\n",
    "  return heatmap , output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZotxII3Hhg0X"
   },
   "outputs": [],
   "source": [
    "heatmap , output = compute_cam(model ,'conv2d_4' , resized )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IlTj-94htYG"
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
    "# display the original image and resulting heatmap and output image\n",
    "# to our screen\n",
    "output = np.vstack([resized, heatmap, output])\n",
    "output = imutils.resize(output, height=700)\n",
    "from google.colab.patches import cv2_imshow\n",
    "cv2_imshow(output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx_AVhhXC8hk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
